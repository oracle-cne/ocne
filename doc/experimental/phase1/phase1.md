# Phase One: Verrazzano Migration

### Version: v0.0.21-draft

The instructions must be performed in the sequence outlined in this document.

## Prerequisites
Set the environment variable KUBECONFIG to point to your cluster kubeconfig.

## Install Oracle Cloud Native Environment 2.0 CLI

Follow these [instructions](https://docs.oracle.com/en/operating-systems/olcne/2.0/cli/ocne_install_task.html#ocne_install) to install the 2.0 CLI on the cluster.

## Install Oracle Cloud Native Environment 2.0 Catalog and UI

```text
ocne cluster start --provider none --kubeconfig $KUBECONFIG --auto-start-ui false
kubectl -n ocne-system rollout status deployment ocne-catalog
```

## Perform an ETCD Backup
Follow these [instructions](../../cluster-management/etcd-backup.md) to backup the ETCD database.

## Perform a Cluster Dump
Perform a cluster dump to take snapshot of the cluster state before the migration begins.
This may take several minutes, it varies depending on the size of your cluster and number of cluster objects.
If you want to redact sensitive information, such as host names, or omit configmaps, then remove the
respective flags:

```text
ocne cluster dump --kubeconfig $KUBECONFIG --skip-redaction --include-configmaps -d /tmp/dump/before-phase1
```

## Remove the Verrazzano controllers
Follow these [instructions](../phase1/disable-verrazzano.md) to remove the Verrazzano controllers on the cluster.

## OAM Migration
This section describes how to migrate from using OAM resources.

### Generate Kubernetes Manifests
Because OAM will no longer be used, you need to generate Kubernetes manifest YAML files for
the Kubernetes resources running in the cluster, that were generated by the Verrazzano controllers
as a result of processing OAM resources. This must be done before you can remove OAM resources, as described in the next section.

[Generate Kubernetes Manifests from OAM](../phase1/oam-to-kubernetes.md)

### Remove OAM resources
Follow these [instructions](../phase1/oam-remove-objects.md) to remove the OAM resources.

## Upgrade to Istio 1.19.9

Follow these [instructions](../phase1/upgrade-istio.md) to upgrade Istio.

## Modify cert-manager Helm overrides

Verrazzano deployed cert-manager using Helm overrides to specify the container images.
Update the existing installation to remove those overrides,
and instead Helm will get the container image values from the defaults in the catalog.

Export the user supplied overrides of the current release to a file and remove the image overrides:
```text
helm get values -n cert-manager cert-manager > overrides.yaml
sed -i '1d' overrides.yaml
sed -i '/image:/,+2d' overrides.yaml
sed -i 's,ghcr.io/verrazzano/cert-manager-acmesolver:v1.9.1-20240724165802-4c06aea1,olcne/cert-manager-acmesolver:v1.9.1,' overrides.yaml
sed -i '1i installCRDs: false' overrides.yaml
```

Update the existing installation:
```text
ocne application update --release cert-manager --namespace cert-manager --version 1.9.1 --reset-values --values overrides.yaml
```

Wait for the update to complete:
```text
kubectl rollout status deployment --namespace cert-manager cert-manager -w
kubectl rollout status deployment --namespace cert-manager cert-manager-cainjector -w
kubectl rollout status deployment --namespace cert-manager cert-manager-webhook -w
```

## Upgrade OpenSearch 2.3.0 to 2.15.0

Follow these [instructions](../phase1/upgrade-opensearch.md) to upgrade OpenSearch.

## Upgrade OpenSearch Dashboards 2.3.0 to 2.15.0

Follow these [instructions](../phase1/upgrade-opensearch-dashboards.md) to upgrade OpenSearch Dashboards.

## Modify WebLogic Kubernetes Operator Helm overrides

Verrazzano deployed the WebLogic Kubernetes Operator using Helm overrides to specify the container images. Update the existing installation to remove those overrides, and instead Helm will get the container images values from the defaults in the catalog.

The following example assumes WebLogic Kubernetes Operator 4.2.5 is already installed.

Add the WebLogic Kubernetes Operator Helm repo:
```text
helm repo add weblogic-operator https://oracle.github.io/weblogic-kubernetes-operator/charts --force-update  
```

Pull the chart from the repo:
```text
helm pull weblogic-operator/weblogic-operator --version 4.2.5
```

Export the user supplied overrides of the current release to a file and remove the image overrides:
```text
helm get values -n verrazzano-system weblogic-operator > overrides.yaml
sed -i '1d' overrides.yaml
sed -i '/image:/d' overrides.yaml
sed -i '/weblogicMonitoringExporterImage:/d' overrides.yaml
```

Update the existing WebLogic Operator:
```text
helm upgrade weblogic-operator ./weblogic-operator-4.2.5.tgz --namespace verrazzano-system  --reset-values --values overrides.yaml
```

Wait for the update to complete:
```text
kubectl rollout status deployment --namespace verrazzano-system weblogic-operator -w
```


## Modify Fluentd Helm overrides

Verrazzano deployed Fluentd using Helm overrides to specify the container images. Update the existing installation to remove those overrides, and instead Helm will get the container images values from the defaults in the catalog.

Export the user supplied overrides of the current release to a file and remove the image overrides:
```text
helm get values -n verrazzano-system fluentd > overrides.yaml
sed -i '1d' overrides.yaml
sed -i '/fluentdImage:/d' overrides.yaml
```

Update the existing installation:
```text
ocne application update --release fluentd --namespace verrazzano-system --version 1.14.5 --reset-values --values overrides.yaml
```

Wait for the update to complete:
```text
kubectl rollout status daemonset --namespace verrazzano-system fluentd -w
```

## Upgrade ingress-nginx from 1.7.1 to 1.9.6

Verrazzano deployed ingress-nginx using Helm overrides to specify the container images.
Update the existing installation to remove those overrides, 
and instead Helm will get the container image values from the defaults in the catalog.

Export the user supplied overrides of the current release to a file and remove the image overrides:
```text
helm get values -n verrazzano-ingress-nginx ingress-controller > overrides.yaml
sed -i '1d' overrides.yaml
sed -i '/digest:/d' overrides.yaml
sed -i '/image:/,+2d' overrides.yaml
```

Upgrade to ingress-nginx 1.9.6 using the overrides extracted above:
```text
ocne application update --release ingress-controller --namespace verrazzano-ingress-nginx --version 1.9.6 --reset-values --values overrides.yaml
```

Wait for the update to complete:
```text
kubectl rollout status deployment --namespace verrazzano-ingress-nginx ingress-controller-ingress-nginx-controller -w
kubectl rollout status deployment --namespace verrazzano-ingress-nginx ingress-controller-ingress-nginx-defaultbackend -w
```

### Patch verrazzano-authproxy to use ingress-nginx 1.9.6

The helm chart for verrazzano-authproxy is not supported in Oracle Cloud Native Environment 2.0. For phase one the deployment will be patched to use ingress-nginx 1.9.6.  The verrazzano-authproxy will need to be migrated to a supported solution during phase three.

```text
kubectl patch deployment -n verrazzano-system verrazzano-authproxy -p '{"spec": {"template": {"spec": {"containers":[{"name": "verrazzano-authproxy","image": "olcne/ingress-nginx-controller:v1.9.6"}]}}}}' --type=strategic
kubectl rollout status deployment -n verrazzano-system verrazzano-authproxy -w
```

## Modify Grafana to be managed by Helm
 
Follow these [instructions](../phase1/upgrade-grafana.md) to migrate Grafana to be managed by Helm.

## Migrate to kube-prometheus-stack

Follow these [instructions](../phase1/kube-prometheus-stack.md) to migrate the kube-prometheus-stack.

## Upgrade prometheus-node-exporter from 1.3.1 to to 1.6.1

Export the user supplied overrides of the current release to a file and remove the image overrides:
```text
helm get values -n verrazzano-monitoring prometheus-node-exporter > overrides.yaml
sed -i '1d' overrides.yaml
sed -i '/image:/,+2d' overrides.yaml
```

Uninstall prometheus-node-exporter 1.3.1. This is required because the 1.6.1 helm chart contains a different value for `spec.selector.matchLabels`, which Kubernetes rejects as an immutable field.

```text
ocne application uninstall --release prometheus-node-exporter --namespace verrazzano-monitoring
```

Install prometheus-node-exporter 1.6.1 using the overrides extracted above:
```text
ocne application install --release prometheus-node-exporter --name prometheus-node-exporter --namespace verrazzano-monitoring --version 1.6.1 --values overrides.yaml
```
Wait for the update to complete:
```text
kubectl rollout status daemonset --namespace verrazzano-monitoring prometheus-node-exporter -w
```

## Modify kube-state-metrics to be managed by Helm

Export the user supplied overrides of the current release to a file and remove the image overrides:
```text
helm get values -n verrazzano-monitoring kube-state-metrics > overrides.yaml
sed -i '1d' overrides.yaml
sed -i '/image:/,+3d' overrides.yaml
```

Update the existing installation:
```text
ocne application update --release kube-state-metrics --namespace verrazzano-monitoring --version 2.8.2 --reset-values --values overrides.yaml
```

Wait for the update to complete:
```text
kubectl rollout status deployment --namespace verrazzano-monitoring kube-state-metrics -w
```

## Delete the Verrazzano custom resource
This section describes how to delete the Verrazzano custom resource, which is no longer needed.

```text
VZCR=<verrazzano-cr-name>
VZCR_NS=<verrazzano-cr-namespace>

kubectl patch vz -n $VZCR_NS $VZCR -p '{"metadata":{"finalizers":[]}}' --type=merge
kubectl delete vz -n $VZCR_NS $VZCR
```

## Delete the VerrazzanoMonitoringInstance
This section describes how to delete the VerrazzanoMonitoringInstance, which is no longer needed.
This must be done before CRDs are deleted in phase2.

```text
kubectl delete --all --all-namespaces verrazzanomonitoringinstances --cascade=orphan
```
Ensure that it was deleted:
```
kubectl get verrazzanomonitoringinstances -A
```
output:
```
No resources found

```

## Migrate to OAuth2 Proxy

Follow these [instructions](../phase1/oauth2-proxy.md) to migrate from Verrazznao auth-proxy to OAuth2 Proxy

## Perform another Cluster Dump

Perform a cluster dump to take snapshot of the cluster state after phase-1 is done.
This may take several minutes, it varies depending on the size of your cluster and number of cluster objects.
If you want to redact sensitive information, such as host names, or omit configmaps, then remove the
respective flags:

```text
ocne cluster dump --kubeconfig $KUBECONFIG --skip-redaction --include-configmaps -d /tmp/dump/after-phase1
```

---
[Next: Phase Two](../phase2/phase2.md)  
[Previous: Introduction](../introduction.md)
